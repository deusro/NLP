{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deusro/NLP/blob/main/desafio_nlp_emo_event.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea Final del Curso de NLP: Clasificación de Emociones en Tweets\n",
        "\n",
        "- Estudiante: Rodrigo Tenorio Ramirez\n",
        "- Fecha: 25 de agosto de 2025\n",
        "\n",
        "### Introducción\n",
        "Este notebook presenta un estudio exploratorio de tres modelos de Procesamiento de Lenguaje Natural (NLP) aplicados a la tarea de clasificación de emociones en tweets en español. El objetivo es analizar y comparar el rendimiento de diferentes arquitecturas en el dataset EmoEvent, que contiene 8409 tweets anotados con una de las ocho categorías: anger, sadness, joy, disgust, fear, surprise y others.\n",
        "\n",
        "Los modelos a explorar son:\n",
        "- Una Red Neuronal Recurrente (LSTM), adaptada de un modelo de detección de sarcasmo.\n",
        "- Un modelo BERT (BETO), realizando un fine-tuning sobre un modelo pre-entrenado en español.\n",
        "- Un modelo T5 usando fine-tunning.\n",
        "\n",
        "Se realizarán análisis de resultados por cada emoción y por cada evento mencionado en el dataset, incluyendo matrices de confusión y una discusión sobre los hallazgos."
      ],
      "metadata": {
        "id": "6V5tZ17wxdPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Legacy\n",
        "\n",
        "Se añade algunas librerias especiales para hacer correr bert en tensorflow,T5 tendra que ser corrido en pytorch ya que no es posible correrlo de otra forma"
      ],
      "metadata": {
        "id": "7R0ioBJKxdJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Instalar la versión de Keras compatible\n",
        "!pip install tf_keras -q\n",
        "!pip install --upgrade transformers sentencepiece -q\n",
        "# 2. Configurar la variable de entorno para forzar el uso de Keras 2\n",
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification"
      ],
      "metadata": {
        "id": "9bAJJLVSxbVO",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:08:01.031140Z",
          "iopub.execute_input": "2025-08-28T10:08:01.031865Z",
          "iopub.status.idle": "2025-08-28T10:08:54.475405Z",
          "shell.execute_reply.started": "2025-08-28T10:08:01.031835Z",
          "shell.execute_reply": "2025-08-28T10:08:54.474625Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Carga y Exploración de Datos (EDA)\n",
        "El primer paso es obtener los datos del repositorio de EmoEvent y realizar un análisis exploratorio para entender su estructura y distribución.\n",
        "### 1.1. Carga de Datos\n",
        "Los datos están divididos en tres archivos (entrenamiento, validación y prueba). Los cargaremos en DataFrames de Pandas."
      ],
      "metadata": {
        "id": "wQROr6w1xsVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# URLs de los datos crudos desde el repositorio de GitHub\n",
        "train_url = 'https://raw.githubusercontent.com/fmplaza/EmoEvent/f55f01c78e77fb2c711b40f3ff6925f605bc5101/splits/es/train.tsv'\n",
        "val_url = 'https://raw.githubusercontent.com/fmplaza/EmoEvent/f55f01c78e77fb2c711b40f3ff6925f605bc5101/splits/es/dev.tsv'\n",
        "test_url = 'https://raw.githubusercontent.com/fmplaza/EmoEvent/f55f01c78e77fb2c711b40f3ff6925f605bc5101/splits/es/test.tsv'\n",
        "\n",
        "# Cargar los datos especificando el separador de TABULADOR\n",
        "column_names = ['id', 'event', 'tweet', 'offensive', 'emotion']\n",
        "df_train = pd.read_csv(train_url, sep='\\t', header=None, names=column_names, skiprows=[0])\n",
        "df_val = pd.read_csv(val_url, sep='\\t', header=None, names=column_names, skiprows=[0])\n",
        "df_test = pd.read_csv(test_url, sep='\\t', header=None, names=column_names, skiprows=[0])\n",
        "\n",
        "print(\"Datos de entrenamiento cargados:\", df_train.shape)\n",
        "print(\"Datos de validación cargados:\", df_val.shape)\n",
        "print(\"Datos de prueba cargados:\", df_test.shape)\n",
        "\n",
        "print(\"\\nPrimeras filas del dataset de entrenamiento:\")\n",
        "print(df_train.head())"
      ],
      "metadata": {
        "id": "mU2egO26xcMf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:08:59.468967Z",
          "iopub.execute_input": "2025-08-28T10:08:59.469505Z",
          "iopub.status.idle": "2025-08-28T10:09:00.631918Z",
          "shell.execute_reply.started": "2025-08-28T10:08:59.469479Z",
          "shell.execute_reply": "2025-08-28T10:09:00.631184Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Análisis Exploratorio de Datos (EDA)\n",
        "Ahora, analizaremos la distribución de las emociones y los eventos en el conjunto de entrenamiento para comprender mejor los datos."
      ],
      "metadata": {
        "id": "AZttOI1QyHAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_full = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
        "\n",
        "# 1. Distribución de Emociones\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(y='emotion', data=df_full, order=df_full['emotion'].value_counts().index, palette='viridis')\n",
        "plt.title('Distribución de Emociones en el Dataset EmoEvent')\n",
        "plt.xlabel('Número de Tweets')\n",
        "plt.ylabel('Emoción')\n",
        "plt.show()\n",
        "\n",
        "# 2. Distribución de Eventos\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.countplot(y='event', data=df_full, order=df_full['event'].value_counts().index, palette='plasma')\n",
        "plt.title('Distribución de Eventos en el Dataset EmoEvent')\n",
        "plt.xlabel('Número de Tweets')\n",
        "plt.ylabel('Evento')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KcLST_5dyGtr",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:09:42.743013Z",
          "iopub.execute_input": "2025-08-28T10:09:42.743457Z",
          "iopub.status.idle": "2025-08-28T10:09:43.058043Z",
          "shell.execute_reply.started": "2025-08-28T10:09:42.743433Z",
          "shell.execute_reply": "2025-08-28T10:09:43.057366Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Observaciones del EDA:**\n",
        "*   **Emociones:** Existe un desbalance significativo entre las clases. La emoción `other` es la más frecuente, seguida por `joy` y `sadness`. Las emociones como `fear` y `disgust` tienen muy pocas muestras, lo que podría dificultar el entrenamiento y la evaluación de los modelos para estas categorías.\n",
        "*   **Eventos:** Los tweets están distribuidos entre varios eventos, siendo `GameOfThrones`, `NotreDame` y `Venezuela` los más prominentes. El análisis por evento será clave para entender si los modelos generalizan bien o si su rendimiento depende del contexto temático.\n"
      ],
      "metadata": {
        "id": "Yu7O9zZbyXBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Preprocesamiento de Texto**\n",
        "\n",
        "Para preparar los datos para los modelos, realizaremos un preprocesamiento estándar que incluye la limpieza de texto y la codificación de las etiquetas."
      ],
      "metadata": {
        "id": "HrXcHlwhyfo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    \"\"\"\n",
        "    Función para limpiar el texto de un tweet.\n",
        "    - Elimina URLs\n",
        "    - Elimina menciones de usuario y hashtags\n",
        "    - Elimina caracteres no alfanuméricos\n",
        "    - Convierte a minúsculas\n",
        "    \"\"\"\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
        "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
        "    tweet = tweet.lower()\n",
        "    return tweet.strip()\n",
        "\n",
        "# --- CORRECCIÓN AQUÍ ---\n",
        "# Convertir toda la columna a string ANTES de aplicar la función de limpieza.\n",
        "# Esto manejará cualquier valor NaN (float) que pueda haber.\n",
        "df_train['clean_tweet'] = df_train['tweet'].astype(str).apply(preprocess_tweet)\n",
        "df_val['clean_tweet'] = df_val['tweet'].astype(str).apply(preprocess_tweet)\n",
        "df_test['clean_tweet'] = df_test['tweet'].astype(str).apply(preprocess_tweet)\n",
        "\n",
        "# Codificar las etiquetas de texto a números\n",
        "label_encoder = LabelEncoder()\n",
        "df_train['emotion_encoded'] = label_encoder.fit_transform(df_train['emotion'])\n",
        "df_val['emotion_encoded'] = label_encoder.transform(df_val['emotion'])\n",
        "df_test['emotion_encoded'] = label_encoder.transform(df_test['emotion'])\n",
        "\n",
        "# Mapeo de etiquetas para referencia futura\n",
        "emotion_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
        "print(\"Mapeo de etiquetas a números:\", emotion_mapping)\n",
        "print(\"\\nEjemplo de tweet preprocesado:\")\n",
        "print(\"Original:\", df_train['tweet'][0])\n",
        "print(\"Limpio:\", df_train['clean_tweet'][0])"
      ],
      "metadata": {
        "id": "Lq3zIkx6yf6i",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:09:47.313725Z",
          "iopub.execute_input": "2025-08-28T10:09:47.314301Z",
          "iopub.status.idle": "2025-08-28T10:09:47.407604Z",
          "shell.execute_reply.started": "2025-08-28T10:09:47.314275Z",
          "shell.execute_reply": "2025-08-28T10:09:47.407069Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Modelo 1: Red Neuronal Recurrente (LSTM)\n",
        "Usaremos un  modelo LSTM hecho en tensorflow, no tiene muchas capas lo que hace que sea menos presiso pero más rapido en su entrenamiento, lo usaremos para que sea un multiclase de nuestras 7 emociones.\n"
      ],
      "metadata": {
        "id": "VE67donyymEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Tokenización y Padding\n",
        "Primero, convertimos las secuencias de texto en secuencias de enteros y las rellenamos para que todas tengan la misma longitud."
      ],
      "metadata": {
        "id": "Xd5Xd_ZZytPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Parámetros para la tokenización\n",
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "embedding_dim = 16\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "# Preparar datos\n",
        "X_train = df_train['clean_tweet'].values\n",
        "y_train = df_train['emotion_encoded'].values\n",
        "X_val = df_val['clean_tweet'].values\n",
        "y_val = df_val['emotion_encoded'].values\n",
        "X_test = df_test['clean_tweet'].values\n",
        "y_test = df_test['emotion_encoded'].values\n",
        "\n",
        "# Inicializar y ajustar el Tokenizer\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convertir textos a secuencias y aplicar padding\n",
        "X_train_padded = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "X_val_padded = pad_sequences(tokenizer.texts_to_sequences(X_val), maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "X_test_padded = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "id": "UFFIQBZVywho",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:09:50.659037Z",
          "iopub.execute_input": "2025-08-28T10:09:50.659303Z",
          "iopub.status.idle": "2025-08-28T10:09:51.093152Z",
          "shell.execute_reply.started": "2025-08-28T10:09:50.659286Z",
          "shell.execute_reply": "2025-08-28T10:09:51.092389Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Construcción y Entrenamiento del Modelo LSTM\n",
        "Definimos la arquitectura del modelo. Lo principal es en la capa de salida: usamos 7 neuronas (una por emoción) y la función de activación softmax para clasificación multiclase. La función de pérdida será `sparse_categorical_crossentropy`."
      ],
      "metadata": {
        "id": "p42BYB1KyxhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(7, activation='softmax') # 7 neuronas para 7 emociones\n",
        "])\n",
        "\n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model_lstm.build(input_shape=(None, max_length))\n",
        "model_lstm.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "TA8LoYmXy8LV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:09:53.602248Z",
          "iopub.execute_input": "2025-08-28T10:09:53.602516Z",
          "iopub.status.idle": "2025-08-28T10:09:56.801481Z",
          "shell.execute_reply.started": "2025-08-28T10:09:53.602493Z",
          "shell.execute_reply": "2025-08-28T10:09:56.800987Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "history_lstm = model_lstm.fit(X_train_padded, y_train,\n",
        "                              epochs=10,\n",
        "                              validation_data=(X_val_padded, y_val),\n",
        "                              verbose=2)"
      ],
      "metadata": {
        "id": "WIwoiN9dsTBB",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:09:59.469186Z",
          "iopub.execute_input": "2025-08-28T10:09:59.469456Z",
          "iopub.status.idle": "2025-08-28T10:11:04.161030Z",
          "shell.execute_reply.started": "2025-08-28T10:09:59.469436Z",
          "shell.execute_reply": "2025-08-28T10:11:04.160467Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Evaluación del Modelo LSTM\n",
        "Evaluamos el modelo con el conjunto de prueba, generando un reporte de clasificación y una matriz de confusión."
      ],
      "metadata": {
        "id": "TwXdYUZCzAEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Predicciones\n",
        "y_pred_lstm_probs = model_lstm.predict(X_test_padded)\n",
        "\n",
        "\n",
        "y_pred_lstm = np.argmax(y_pred_lstm_probs, axis=1)\n",
        "\n",
        "# Reporte de Clasificación\n",
        "print(\"--- Reporte de Clasificación - Modelo LSTM ---\")\n",
        "print(classification_report(y_test, y_pred_lstm, target_names=label_encoder.classes_))\n",
        "\n",
        "# Matriz de Confusión\n",
        "cm_lstm = confusion_matrix(y_test, y_pred_lstm)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_lstm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title('Matriz de Confusión - Modelo LSTM')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.xlabel('Etiqueta Predicha')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lFSmmBqUzDIa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:11:07.610131Z",
          "iopub.execute_input": "2025-08-28T10:11:07.610836Z",
          "iopub.status.idle": "2025-08-28T10:11:10.635823Z",
          "shell.execute_reply.started": "2025-08-28T10:11:07.610813Z",
          "shell.execute_reply": "2025-08-28T10:11:10.635059Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de Resultados LSTM:\n",
        "- El modelo LSTM muestra un rendimiento moderado. Logra una buena precisión para las clases mayoritarias como joy y others.\n",
        "- Sin embargo, sufre en las clases con menos datos como disgust, surprise y fear, donde la precisión y el recall son muy bajos. Esto era de esperar debido al desbalance de clases observado en el EDA.\n",
        "- La matriz de confusión muestra que muchos errores consisten en clasificar incorrectamente las emociones minoritarias como other.\n",
        "\n",
        "- El modelo es completamente incapaz de identificar las emociones disgust y fear.\n",
        "- Rendimiento Muy Pobre en Otras Clases: Para anger, sadness y surprise, el rendimiento es extremadamente bajo. Por ejemplo, de 67 tweets de surprise, solo acertó 7.\n"
      ],
      "metadata": {
        "id": "0DQx46kGzHum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Modelo 2: Fine-Tuning de BERT (BETO)\n",
        "Para este modelo, utilizaremos \"BETO\", una versión de BERT pre-entrenada con un gran corpus en español. Haremos un fine-tuning para la tarea específica de clasificación de emociones."
      ],
      "metadata": {
        "id": "wcps5yJWzRou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Preparación de Datos y Tokenización para BERT\n",
        "El proceso de tokenización para BERT es diferente; utiliza su propio tokenizador que maneja sub-palabras y tokens especiales como [CLS] y [SEP]."
      ],
      "metadata": {
        "id": "zfKrR6oRzT2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el tokenizador de BETO\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
        "\n",
        "# Tokenizar los datos\n",
        "def bert_tokenizer_fn(texts, tokenizer):\n",
        "    return tokenizer(\n",
        "        texts, padding='max_length', truncation=True, max_length=128, return_tensors='tf'\n",
        "    )\n",
        "\n",
        "X_train_bert = bert_tokenizer_fn(df_train['clean_tweet'].tolist(), tokenizer_bert)\n",
        "X_val_bert = bert_tokenizer_fn(df_val['clean_tweet'].tolist(), tokenizer_bert)\n",
        "X_test_bert = bert_tokenizer_fn(df_test['clean_tweet'].tolist(), tokenizer_bert)"
      ],
      "metadata": {
        "id": "5XrxhuK8zWl5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:11:56.573874Z",
          "iopub.execute_input": "2025-08-28T10:11:56.574565Z",
          "iopub.status.idle": "2025-08-28T10:12:00.399913Z",
          "shell.execute_reply.started": "2025-08-28T10:11:56.574542Z",
          "shell.execute_reply": "2025-08-28T10:12:00.399305Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2. Construcción y Fine-Tuning del Modelo**\n",
        "\n",
        "Utilizaremos la arquitectura `TFBertForSequenceClassification` de la librería `transformers`, configurándola para 8 etiquetas de salida."
      ],
      "metadata": {
        "id": "XgkEI9Knza_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo pre-entrenado\n",
        "model_bert = TFBertForSequenceClassification.from_pretrained('dccuchile/bert-base-spanish-wwm-cased', num_labels=8)\n",
        "\n",
        "# Compilar el modelo (\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model_bert.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "# Entrenar (fine-tuning)\n",
        "history_bert = model_bert.fit(\n",
        "    {'input_ids': X_train_bert['input_ids'], 'attention_mask': X_train_bert['attention_mask']},\n",
        "    y_train,\n",
        "    validation_data=({'input_ids': X_val_bert['input_ids'], 'attention_mask': X_val_bert['attention_mask']}, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "ZIfKti1OzdB9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:12:29.501947Z",
          "iopub.execute_input": "2025-08-28T10:12:29.502223Z",
          "iopub.status.idle": "2025-08-28T10:37:23.990936Z",
          "shell.execute_reply.started": "2025-08-28T10:12:29.502200Z",
          "shell.execute_reply": "2025-08-28T10:37:23.990153Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4.3. Evaluación del Modelo BERT"
      ],
      "metadata": {
        "id": "sujsFUW6zfKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones\n",
        "logits_bert = model_bert.predict({'input_ids': X_test_bert['input_ids'], 'attention_mask': X_test_bert['attention_mask']}).logits\n",
        "y_pred_bert = np.argmax(logits_bert, axis=1)\n",
        "\n",
        "# Reporte de Clasificación\n",
        "print(\"\\n--- Reporte de Clasificación - Modelo BERT (BETO) ---\")\n",
        "print(classification_report(y_test, y_pred_bert, target_names=label_encoder.classes_))\n",
        "\n",
        "# Matriz de Confusión\n",
        "cm_bert = confusion_matrix(y_test, y_pred_bert)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_bert, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title('Matriz de Confusión - Modelo BERT (BETO)')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.xlabel('Etiqueta Predicha')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vmtr-T2uziZS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T10:41:27.120455Z",
          "iopub.execute_input": "2025-08-28T10:41:27.120799Z",
          "iopub.status.idle": "2025-08-28T10:41:45.331158Z",
          "shell.execute_reply.started": "2025-08-28T10:41:27.120771Z",
          "shell.execute_reply": "2025-08-28T10:41:45.330388Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de Resultados BERT:\n",
        "- BERT (BETO) muestra una pequeña sobre el modelo LSTM.\n",
        "\n",
        "- Mismo Fallo en Clases Minoritarias: Al igual que el LSTM, BERT es completamente incapaz de identificar disgust y fear. Esto demuestra que ni siquiera un modelo pre-entrenado tan potente puede hacer magia si no tiene suficientes ejemplos para aprender.\n",
        "- Ligera Mejora en la precisión general, el accuracy sube del 33% al 36%.\n",
        "- hay un mismo sesgo hacia la columna de others en la matriz de confusión de BERT es aún más dominante que en la del LSTM. BERT se ha vuelto aún más \"seguro\" de que predecir others es la mejor estrategia, lo que explica su mayor F1-score en esa clase (0.54 vs 0.51)."
      ],
      "metadata": {
        "id": "_1fAcy4fzkV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Modelo 3: Clasificación con T5\n",
        "Se usara T5 implementado en pytorch."
      ],
      "metadata": {
        "id": "LtsBSROIzrDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### liberacion de espacio"
      ],
      "metadata": {
        "id": "14R4cGLKn3Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import gc # Garbage Collector\n",
        "\n",
        "\n",
        "print(\"--- Liberando memoria de la GPU ---\")\n",
        "\n",
        "del model_lstm\n",
        "del model_bert\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print(\"Memoria liberada.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T11:34:45.027755Z",
          "iopub.execute_input": "2025-08-28T11:34:45.028113Z",
          "iopub.status.idle": "2025-08-28T11:34:46.040410Z",
          "shell.execute_reply.started": "2025-08-28T11:34:45.028090Z",
          "shell.execute_reply": "2025-08-28T11:34:46.039645Z"
        },
        "id": "2VvK7CkPn3Lz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Preparación de Datos y Creación de Datasets en PyTorch\n"
      ],
      "metadata": {
        "id": "2T2rg-oOzweb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "prefix = \"clasificar emocion: \"\n",
        "X_train_t5 = [prefix + tweet for tweet in df_train['clean_tweet']]\n",
        "X_val_t5 = [prefix + tweet for tweet in df_val['clean_tweet']]\n",
        "X_test_t5 = [prefix + tweet for tweet in df_test['clean_tweet']]\n",
        "\n",
        "y_train_text = label_encoder.inverse_transform(df_train['emotion_encoded'])\n",
        "y_val_text = label_encoder.inverse_transform(df_val['emotion_encoded'])\n",
        "y_test_text = label_encoder.inverse_transform(df_test['emotion_encoded'])\n",
        "\n",
        "tokenizer_t5 = T5Tokenizer.from_pretrained('google-t5/t5-base')\n"
      ],
      "metadata": {
        "id": "kXLLJyozzqRc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T11:34:50.959177Z",
          "iopub.execute_input": "2025-08-28T11:34:50.959420Z",
          "iopub.status.idle": "2025-08-28T11:34:51.330011Z",
          "shell.execute_reply.started": "2025-08-28T11:34:50.959405Z",
          "shell.execute_reply": "2025-08-28T11:34:51.329448Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  5.2. Crear una clase de Dataset para PyTorch"
      ],
      "metadata": {
        "id": "LcEqSOJEAEFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, tweets, labels, tokenizer, max_input_len, max_target_len):\n",
        "        self.tweets = tweets\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_len = max_input_len\n",
        "        self.max_target_len = max_target_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tweets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        tweet = self.tweets[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Tokenizar la entrada\n",
        "        source = self.tokenizer.batch_encode_plus(\n",
        "            [tweet],\n",
        "            max_length=self.max_input_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Tokenizar la salida\n",
        "        target = self.tokenizer.batch_encode_plus(\n",
        "            [label],\n",
        "            max_length=self.max_target_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": source[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": source[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": target[\"input_ids\"].squeeze()\n",
        "        }\n",
        "\n",
        "# 5. Instanciar los Datasets\n",
        "train_dataset = EmotionDataset(X_train_t5, y_train_text, tokenizer_t5, 128, 7)\n",
        "val_dataset = EmotionDataset(X_val_t5, y_val_text, tokenizer_t5, 128, 7)\n",
        "test_dataset = EmotionDataset(X_test_t5, y_test_text, tokenizer_t5, 128, 7)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "QYEndRMaAGJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T11:35:17.673139Z",
          "iopub.execute_input": "2025-08-28T11:35:17.673401Z",
          "iopub.status.idle": "2025-08-28T11:35:17.679847Z",
          "shell.execute_reply.started": "2025-08-28T11:35:17.673381Z",
          "shell.execute_reply": "2025-08-28T11:35:17.679229Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3. Construcción y Fine-Tuning del Modelo T5 con PyTorch"
      ],
      "metadata": {
        "id": "vagi2l-xQSM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Configurar el dispositivo (usar GPU si está disponible), sin GPU esto demora horas, se uso GPU T4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# 2. Cargar el modelo y enviarlo al dispositivo\n",
        "model_t5 = T5ForConditionalGeneration.from_pretrained('google-t5/t5-base').to(device)\n",
        "\n",
        "# 3. Crear DataLoaders para manejar los lotes de datos, en teoria lo hace más optimo pero no encontre mejora notable.\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# 4. Configurar el optimizador\n",
        "optimizer = AdamW(model_t5.parameters(), lr=3e-5)\n",
        "\n",
        "# 5. Bucle de Entrenamiento Manual, sacado de stackoverflow pero creo que hay una funcion para reducir todo el codigo manual a unas cuenta lineas\n",
        "# Investigar más sobre pytorch\n",
        "print(\"\\n--- Iniciando Fine-Tuning de T5 con PyTorch ---\")\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    model_t5.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        # Mover los datos del lote al dispositivo\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Limpiar gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_t5(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Actualizar pesos\n",
        "        optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} - Pérdida de entrenamiento promedio: {avg_train_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "eealW5zLQRA-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T11:35:19.971446Z",
          "iopub.execute_input": "2025-08-28T11:35:19.971725Z",
          "iopub.status.idle": "2025-08-28T11:41:02.890630Z",
          "shell.execute_reply.started": "2025-08-28T11:35:19.971705Z",
          "shell.execute_reply": "2025-08-28T11:41:02.890005Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4. Evaluación del Modelo T5\n"
      ],
      "metadata": {
        "id": "KO5Xd6E1B9KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"\\n--- Generando predicciones con T5 ---\")\n",
        "model_t5.eval()\n",
        "predictions = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Prediciendo\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        generated_ids = model_t5.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=8\n",
        "        )\n",
        "\n",
        "        preds = tokenizer_t5.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "        predictions.extend(preds)\n",
        "\n",
        "# Reporte de Clasificación\n",
        "print(\"\\n--- Reporte de Clasificación - Modelo T5 ---\")\n",
        "print(classification_report(\n",
        "    y_test_text,\n",
        "    predictions,\n",
        "    target_names=label_encoder.classes_,\n",
        "    labels=label_encoder.classes_,  # <--- Le decimos todas las clases posibles\n",
        "    zero_division=0                 # <--- Le decimos que ponga 0 si hay división por cero\n",
        "))\n",
        "\n",
        "# Matriz de Confusión\n",
        "cm_t5 = confusion_matrix(y_test_text, predictions, labels=label_encoder.classes_)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_t5, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title('Matriz de Confusión - Modelo T5')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.xlabel('Etiqueta Predicha')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tr51pzfsB6Wk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T11:44:40.861160Z",
          "iopub.execute_input": "2025-08-28T11:44:40.861425Z",
          "iopub.status.idle": "2025-08-28T11:44:57.849351Z",
          "shell.execute_reply.started": "2025-08-28T11:44:40.861408Z",
          "shell.execute_reply": "2025-08-28T11:44:57.848673Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de Resultados de T5:\n",
        "- Una Pequeña Luz en las Clases Minoritarias: A diferencia del LSTM y BERT, que obtuvieron un F1-score de 0.00 en disgust y fear, el modelo T5 logra hacer algunas predicciones correctas, aunque muy pocas. los resultados son numéricamente terrible, pero cualitativamente importante: significa que el modelo no es completamente ciego a estas categorías, a diferencia de los otros dos.\n",
        "- El Sesgo Hacia others y joy Persiste, al igual que los modelos anteriores, T5 sufre masivamente del desbalance de clases. La matriz de confusión muestra que la gran mayoría de las predicciones incorrectas caen en la co0lumna others.\n"
      ],
      "metadata": {
        "id": "oMChY_wjCCCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Análisis Comparativo y por Eventos\n"
      ],
      "metadata": {
        "id": "l0THCVZQCH2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1. Comparación General de Modelos"
      ],
      "metadata": {
        "id": "5AKEixTkCTiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Modelo | Accuracy (General) | F1-Score (Macro Avg) | Fortalezas | Debilidades |\n",
        "| :--- | :---: | :---: | :--- | :--- |\n",
        "| LSTM | 33% | 0.15 | Arquitectura simple y rápida de entrenar. | Completamente incapaz de identificar clases minoritarias (disgust, fear). Muy bajo rendimiento general. |\n",
        "| BERT (BETO) | 36% | 0.15 | Ligeramente mejor en predecir correctamente las clases mayoritarias (others, joy). | Falla completamente en clases minoritarias, igual que el LSTM. El poder del pre-entrenamiento no supera el desbalance. |\n",
        "| T5 | 35% | 0.18 | Único modelo que no falló por completo en las clases minoritarias. Mejor F1-score macro. | Rendimiento general bajo. Precisión muy pobre en clases minoritarias, aunque el recall no sea cero. |"
      ],
      "metadata": {
        "id": "LRcmmpCDCddT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. Análisis por Evento\n",
        "Ahora, evaluaremos el rendimiento del mejor modelo, BETO, en cada uno de los eventos del conjunto de prueba"
      ],
      "metadata": {
        "id": "hwm3E8yDCWwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(22, 7), sharey=True)\n",
        "fig.suptitle('Comparación de Accuracy por Evento para cada Modelo', fontsize=16)\n",
        "\n",
        "\n",
        "\n",
        "# Modelo 1: LSTM\n",
        "# La DeprecationWarning aparecerá aquí, pero es seguro ignorarla.\n",
        "accuracy_lstm = df_test.groupby('event').apply(\n",
        "    lambda x: accuracy_score(x['emotion_encoded'], x['lstm_prediction'])\n",
        ").sort_values()\n",
        "\n",
        "accuracy_lstm.plot(kind='barh', ax=axes[0], color=sns.color_palette('viridis', len(accuracy_lstm)))\n",
        "axes[0].set_title('Modelo LSTM')\n",
        "axes[0].set_xlabel('Accuracy')\n",
        "axes[0].set_ylabel('Evento')\n",
        "axes[0].set_xlim(0, 1)\n",
        "\n",
        "# Modelo 2: BERT (BETO)\n",
        "accuracy_bert = df_test.groupby('event').apply(\n",
        "    lambda x: accuracy_score(x['emotion_encoded'], x['bert_prediction'])\n",
        ").sort_values()\n",
        "\n",
        "accuracy_bert.plot(kind='barh', ax=axes[1], color=sns.color_palette('plasma', len(accuracy_bert)))\n",
        "axes[1].set_title('Modelo BERT (BETO)')\n",
        "axes[1].set_xlabel('Accuracy')\n",
        "axes[1].set_xlim(0, 1)\n",
        "\n",
        "# Modelo 3: T5\n",
        "accuracy_t5 = df_test.groupby('event').apply(\n",
        "    lambda x: accuracy_score(x['emotion_encoded'], x['t5_prediction'])\n",
        ").sort_values()\n",
        "\n",
        "accuracy_t5.plot(kind='barh', ax=axes[2], color=sns.color_palette('magma', len(accuracy_t5)))\n",
        "axes[2].set_title('Modelo T5')\n",
        "axes[2].set_xlabel('Accuracy')\n",
        "axes[2].set_xlim(0, 1)\n",
        "\n",
        "# Ajustar el layout y mostrar el gráfico\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n",
        "\n",
        "# --- Paso 4: Imprimir los resultados numéricos ---\n",
        "print(\"--- Accuracy por Evento - Modelo LSTM ---\")\n",
        "print(accuracy_lstm.sort_values(ascending=False))\n",
        "print(\"\\n--- Accuracy por Evento - Modelo BERT (BETO) ---\")\n",
        "print(accuracy_bert.sort_values(ascending=False))\n",
        "print(\"\\n--- Accuracy por Evento - Modelo T5 ---\")\n",
        "print(accuracy_t5.sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "AF8exyldCV8j",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-28T12:01:06.972398Z",
          "iopub.execute_input": "2025-08-28T12:01:06.972691Z",
          "iopub.status.idle": "2025-08-28T12:01:07.543448Z",
          "shell.execute_reply.started": "2025-08-28T12:01:06.972672Z",
          "shell.execute_reply": "2025-08-28T12:01:07.542703Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. Análisis Detallado por Evento\n",
        "- El análisis del rendimiento de cada modelo por evento revela patrones muy interesantes que no son visibles en las métricas agregadas. Confirma que el contexto temático del tweet es un factor crucial en la dificultad de la clasificación.\n",
        "\n",
        "- Evento Más Fácil (GretaThunberg): Los tres modelos obtienen su mejor rendimiento al clasificar tweets sobre Greta Thunberg (45-47% de accuracy). Esto sugiere que el lenguaje y las emociones expresadas en este contexto son más directas y menos ambiguas\n",
        "\n",
        "- Evento Más Difícil (NotreDame): Consistentemente, NotreDame es el evento con el peor rendimiento para los modelos LSTM y BERT (21-23%). Un desastre como este genera una mezcla emocional muy compleja: sadness por la pérdida, fear durante el incendio, anger por las posibles causas, surprise por el suceso, y una gran cantidad de tweets informativos (others). Esta ambigüedad confunde a los modelos.\n",
        "\n",
        "  \n",
        "- BERT vs. T5:  Aunque su accuracy general es similar, este análisis revela una diferencia clave. T5 demuestra ser más robusto en el evento más difícil, NotreDame, superando a BERT por casi 10 puntos porcentuales (32% vs 23%)."
      ],
      "metadata": {
        "id": "QOZeimcTCcxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusión\n",
        "- El Desbalance de Clases es el Principal Obstáculo: El hallazgo más importante es que el severo desbalance de clases en el dataset de EmoEvent fue el factor más determinante en el bajo rendimiento general de todos los modelos. La predominancia de la clase others provocó que todos los modelos desarrollaran un fuerte sesgo hacia ella, fallando casi por completo en la identificación de emociones minoritarias como disgust, fear y surprise.\n",
        "\n",
        "- El Contexto Importa: El análisis por evento demostró que la precisión de un clasificador de emociones no es estática, sino que depende en gran medida del dominio temático. Los modelos tuvieron más éxito en contextos polarizados (GretaThunberg) y fallaron en eventos emocionalmente complejos (NotreDame).\n",
        "\n",
        "- Faltaria tener un dataset más balanceado para aumentar el acurracy del modelo\n",
        "\n",
        "- El intento de usar bert en tensorflow demostro ser un gran error, desde importar bibliotecas antiguas y procesos muy tediosos se ve la facilidad que otorga pytorch cuando se necesita usar modelos ya hecho para fine-tunning, por otro lado fue efectivo en el hecho de crear desde cero un lstm."
      ],
      "metadata": {
        "id": "Avej5w0fCjh8"
      }
    }
  ]
}